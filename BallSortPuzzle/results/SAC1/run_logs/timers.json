{
    "name": "root",
    "gauges": {
        "Game.Policy.Entropy.mean": {
            "value": 0.1289699375629425,
            "min": 0.1289699375629425,
            "max": 2.549391031265259,
            "count": 8
        },
        "Game.Policy.Entropy.sum": {
            "value": 6413.93310546875,
            "min": 6413.93310546875,
            "max": 44902.39453125,
            "count": 8
        },
        "Game.Environment.EpisodeLength.mean": {
            "value": 4999.0,
            "min": 184.6315789473684,
            "max": 4999.0,
            "count": 8
        },
        "Game.Environment.EpisodeLength.sum": {
            "value": 69986.0,
            "min": 3508.0,
            "max": 69986.0,
            "count": 8
        },
        "Game.Step.mean": {
            "value": 549940.0,
            "min": 199963.0,
            "max": 549940.0,
            "count": 8
        },
        "Game.Step.sum": {
            "value": 549940.0,
            "min": 199963.0,
            "max": 549940.0,
            "count": 8
        },
        "Game.Policy.ExtrinsicValue.mean": {
            "value": -1.2697559595108032,
            "min": -1.2697559595108032,
            "max": 7.181735038757324,
            "count": 8
        },
        "Game.Policy.ExtrinsicValue.sum": {
            "value": -1006.9164428710938,
            "min": -1006.9164428710938,
            "max": 4457.54833984375,
            "count": 8
        },
        "Game.Environment.CumulativeReward.mean": {
            "value": -50.51428556947836,
            "min": -52.21833340326945,
            "max": -0.5319473900293049,
            "count": 8
        },
        "Game.Environment.CumulativeReward.sum": {
            "value": -707.199997972697,
            "min": -707.199997972697,
            "max": -10.107000410556793,
            "count": 8
        },
        "Game.Policy.ExtrinsicReward.mean": {
            "value": -50.51428556947836,
            "min": -52.21833340326945,
            "max": -0.5319473900293049,
            "count": 8
        },
        "Game.Policy.ExtrinsicReward.sum": {
            "value": -707.199997972697,
            "min": -707.199997972697,
            "max": -10.107000410556793,
            "count": 8
        },
        "Game.Losses.PolicyLoss.mean": {
            "value": 2.276474761928378,
            "min": -15.353740044595417,
            "max": 2.276474761928378,
            "count": 8
        },
        "Game.Losses.PolicyLoss.sum": {
            "value": 113605.19651927378,
            "min": -581041.6386993831,
            "max": 113605.19651927378,
            "count": 8
        },
        "Game.Losses.ValueLoss.mean": {
            "value": 0.00022004996377213555,
            "min": 0.00012979960344873073,
            "max": 0.10636639016474106,
            "count": 8
        },
        "Game.Losses.ValueLoss.sum": {
            "value": 10.981373392084652,
            "min": 6.494133759746895,
            "max": 1110.358746929732,
            "count": 8
        },
        "Game.Losses.Q1Loss.mean": {
            "value": 0.0007419577886761988,
            "min": 0.00020119089138913386,
            "max": 0.17088645611968237,
            "count": 8
        },
        "Game.Losses.Q1Loss.sum": {
            "value": 37.02666148609703,
            "min": 10.065982677981145,
            "max": 7210.179529565223,
            "count": 8
        },
        "Game.Losses.Q2Loss.mean": {
            "value": 0.0005338290113891618,
            "min": 0.0001860980526335718,
            "max": 0.21466634181788993,
            "count": 8
        },
        "Game.Losses.Q2Loss.sum": {
            "value": 26.640202984364734,
            "min": 9.310857769362865,
            "max": 7121.82921642551,
            "count": 8
        },
        "Game.Policy.DiscreteEntropyCoeff.mean": {
            "value": 0.0022204531496016495,
            "min": 0.0013179497427889568,
            "max": 0.3771467912330148,
            "count": 8
        },
        "Game.Policy.DiscreteEntropyCoeff.sum": {
            "value": 110.80949397772072,
            "min": 65.93966153121708,
            "max": 3937.0353536814414,
            "count": 8
        },
        "Game.Policy.ContinuousEntropyCoeff.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 8
        },
        "Game.Policy.ContinuousEntropyCoeff.sum": {
            "value": 49904.0,
            "min": 10439.0,
            "max": 50797.0,
            "count": 8
        },
        "Game.Policy.LearningRate.mean": {
            "value": 1.3643268264074381e-05,
            "min": 1.3643268264074381e-05,
            "max": 0.00019387173278703364,
            "count": 8
        },
        "Game.Policy.LearningRate.sum": {
            "value": 0.6808536594503679,
            "min": 0.6808536594503679,
            "max": 9.015030585054133,
            "count": 8
        },
        "Game.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 8
        },
        "Game.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 8
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1621966854",
        "python_version": "3.7.3 (default, Apr 24 2019, 15:29:51) [MSC v.1915 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\berna\\Desktop\\Iart - proj2\\BallSortPuzzle\\venv\\Scripts\\mlagents-learn --run-id=SAC1 config/config.yaml --resume",
        "mlagents_version": "0.26.0",
        "mlagents_envs_version": "0.26.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.0+cu110",
        "numpy_version": "1.20.3",
        "end_time_seconds": "1621972557"
    },
    "total": 5703.8131016,
    "count": 1,
    "self": 0.007765700000163633,
    "children": {
        "run_training.setup": {
            "total": 0.11848819999999993,
            "count": 1,
            "self": 0.11848819999999993
        },
        "TrainerController.start_learning": {
            "total": 5703.6868477,
            "count": 1,
            "self": 0.2161645999740358,
            "children": {
                "TrainerController._reset_env": {
                    "total": 17.5413663,
                    "count": 1,
                    "self": 17.5413663
                },
                "TrainerController.advance": {
                    "total": 5685.870031700027,
                    "count": 11605,
                    "self": 0.19478410012652603,
                    "children": {
                        "env_step": {
                            "total": 89.31415599994199,
                            "count": 11605,
                            "self": 59.9376774999117,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 29.25195370003355,
                                    "count": 11605,
                                    "self": 0.658359600037965,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 28.593594099995585,
                                            "count": 11605,
                                            "self": 8.145062699999333,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 20.448531399996252,
                                                    "count": 11605,
                                                    "self": 20.448531399996252
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.12452479999673471,
                                    "count": 11605,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 5686.941845900008,
                                            "count": 11605,
                                            "is_parallel": true,
                                            "self": 5644.613117200018,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0006455000000009647,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00024389999999741008,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00040160000000355467,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00040160000000355467
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 42.328083199990346,
                                                    "count": 11605,
                                                    "is_parallel": true,
                                                    "self": 1.7171794999770924,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 3.6800616000437074,
                                                            "count": 11605,
                                                            "is_parallel": true,
                                                            "self": 3.6800616000437074
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 32.21998169998379,
                                                            "count": 11605,
                                                            "is_parallel": true,
                                                            "self": 32.21998169998379
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 4.710860399985759,
                                                            "count": 11605,
                                                            "is_parallel": true,
                                                            "self": 2.309489599994361,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 2.4013707999913976,
                                                                    "count": 23210,
                                                                    "is_parallel": true,
                                                                    "self": 2.4013707999913976
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 5596.361091599958,
                            "count": 11605,
                            "self": 0.6761634999502348,
                            "children": {
                                "process_trajectory": {
                                    "total": 20.07779249998169,
                                    "count": 11605,
                                    "self": 19.98497329998157,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.09281920000012178,
                                            "count": 1,
                                            "self": 0.09281920000012178
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 5575.607135600026,
                                    "count": 11560,
                                    "self": 0.11679099995853903,
                                    "children": {
                                        "SACTrainer._update_policy": {
                                            "total": 5575.490344600067,
                                            "count": 11560,
                                            "self": 416.80178880016956,
                                            "children": {
                                                "TorchSACOptimizer.update": {
                                                    "total": 5158.688555799898,
                                                    "count": 361184,
                                                    "self": 5158.688555799898
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 7.999997251317836e-07,
                    "count": 1,
                    "self": 7.999997251317836e-07
                },
                "TrainerController._save_models": {
                    "total": 0.05928429999949003,
                    "count": 1,
                    "self": 0.001040399999510555,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.058243899999979476,
                            "count": 1,
                            "self": 0.058243899999979476
                        }
                    }
                }
            }
        }
    }
}